# Adversarial Robustness Toolbox (ART) <br> ~~ Evasion Attacks on CNN classification model

## Impact
Evasion attacks are made to drastically reduce the accuracy of a model by manipulating the input data. This works by adding small perturbations to the input, resulting in incorrect predictions and misclassification.
Moreover, many AI systems have potential threats, such as security systems that can incorrectly authorize if an image is predicted in the culprit's desire. This project aims to display the effects and the process of 
how an evasion attack is possible.
